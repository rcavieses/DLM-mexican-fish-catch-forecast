{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 20:50:30.187938: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 20:50:31.104199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-20 20:50:31.104307: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-20 20:50:31.245239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 20:50:31.567022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 20:50:33.485433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ia_model.data_preparation import load_data, prepare_data, split_data\n",
    "from ia_model.model import  train_model, evaluate_model, save_model, build_dynamic_model\n",
    "from ia_model.utils import ia_plot_history\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters for the model and data preparation\n",
    "FILE_PATH = 'aggregated_data4.csv' #This data can be download from https://rcavieses.pythonanywhere.com/\n",
    "FEATURE_COL = ['NOMBRE PRINCIPAL','NOMBRE ESTADO','NOMBRE OFICINA','SST','PESO DESEMBARCADO_KILOGRAMOS']#Change this if you want to add input variables\n",
    "TARGET_COL = 'PESO DESEMBARCADO_KILOGRAMOS'\n",
    "CATEGORICAL_COL = ['NOMBRE PRINCIPAL','NOMBRE ESTADO','NOMBRE OFICINA']\n",
    "NUMERIC_COL = ['PESO DESEMBARCADO_KILOGRAMOS','SST']\n",
    "steps_forecast = 12\n",
    "time_steps= 12 # number of steps that lstm forecast, change this will be errors on scoore metrics ;)\n",
    "layer_type =  ['LSTM','LSTM','Dense'] # add as many layer you need options: Dense or LSTM\n",
    "neurons_per_layer = [10,15,1] #match the number of layers and length of neurons number list\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 30\n",
    "MODEL_PATH = 'mi_modelo.h5'\n",
    "SCALER_X_PATH = 'scaler_X.pkl'\n",
    "SCALER_Y_PATH = 'scaler_Y.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = load_data(str(FILE_PATH))\n",
    "X, y, scaler_x,scaler_y, encoder , n_features = prepare_data(df, TARGET_COL, time_steps,CATEGORICAL_COL,NUMERIC_COL)\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_dynamic_model(time_steps,n_features,layer_type,neurons_per_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model, history = train_model(model, X_train, y_train, X_test, y_test, EPOCHS, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "mse, mae, r2 = evaluate_model(model, X_test, y_test)\n",
    "print(f'MSE: {mse}, MAE: {mae}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia_plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model,'mi_modelo.h5')\n",
    "joblib.dump(scaler_x, 'scaler_X.pkl')  # Saves the scaler\n",
    "joblib.dump(scaler_y, 'scaler_Y.pkl')  # Saves the scaler\n",
    "joblib.dump(encoder, 'encoder_filename.pkl')  # Saves the encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
